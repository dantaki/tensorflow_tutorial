{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import input_data\n",
    "mnist = input_data.read_data_sets(\"data/\", one_hot=True)\n",
    "\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "# Architecture\n",
    "n_hidden_1 = 256\n",
    "n_hidden_2 = 256\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "training_epochs = 100\n",
    "batch_size = 1\n",
    "display_step = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### from the author #####\n",
    "def loss(output, y):\n",
    "    xentropy = tf.nn.softmax_cross_entropy_with_logits(output, y)    \n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "    return loss\n",
    "\n",
    "def training(cost, global_step):\n",
    "    tf.scalar_summary(\"cost\", cost)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    train_op = optimizer.minimize(cost, global_step=global_step)\n",
    "    return train_op\n",
    "\n",
    "\n",
    "def evaluate(output, y):\n",
    "    correct_prediction = tf.equal(tf.argmax(output, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.scalar_summary(\"validation error\", (1.0 - accuracy))\n",
    "    return accuracy\n",
    "\n",
    "def layer(input, weight_shape, bias_shape):\n",
    "    weight_init = tf.random_normal_initializer(stddev=(2.0/weight_shape[0])**0.5)\n",
    "    bias_init = tf.constant_initializer(value=0)\n",
    "    W = tf.get_variable(\"W\", weight_shape,\n",
    "                        initializer=weight_init)\n",
    "    b = tf.get_variable(\"b\", bias_shape,\n",
    "                        initializer=bias_init)\n",
    "    return tf.nn.relu(tf.matmul(input, W) + b)\n",
    "#############################\n",
    "def conv2d(input,weight_shape,bias_shape):\n",
    "    \"\"\"generate a convolutional layer with a particular shape\"\"\"\n",
    "    \"\"\"set stride to be 1 and padding to keep the wifth and height constant\"\"\"\n",
    "    inn=weight_shape[0]*weight_shape[1]*weight_shape[2]\n",
    "    \n",
    "    weight_init=tf.random_normal_initializer(stddev=(2.0/inn)**0.5)\n",
    "    W = tf.get_variable('W',weight_shape,initializer=weight_init)\n",
    "    \n",
    "    bias_init = tf.constant_initializer(value=0)\n",
    "    b = tf.get_variable('b',bias_shape,initializer=bias_init)\n",
    "    \n",
    "    conv_out = tf.nn.conv2d(input,W,strides=[1,1,1,1],padding='SAME')\n",
    "    return tf.nn.relu(tf.nn.bias_add(conv_out,b))\n",
    "\n",
    "def max_pool(input,k=2):\n",
    "    \"\"\"generate a max pooling layer with non-overlapping windows of size k\"\"\"\n",
    "    \"\"\"usually k=2 is recommended\"\"\"\n",
    "    return tf.nn.max_pool(input,ksize=[1,k,k,1],strides=[1,k,k,1],padding='SAME')\n",
    "\n",
    "def inference(x,keep_prob):\n",
    "    # take flattened input pixel and reshape into tensor of N x 28 x 28 x 1\n",
    "    # N = number of examples in a minibatch\n",
    "    # 28 = width & height\n",
    "    # 1 = depth (if RGB depth=3)\n",
    "    x = tf.reshape(x,shape=[-1,28,28,1])\n",
    "    \n",
    "    # build convolutional layer of 32 filters\n",
    "    # with spatial extent of 5\n",
    "    # input tensor of depth 1 -> depth 32\n",
    "    with tf.variable_scope(\"conv_1\"):\n",
    "        conv_1 = conv2d(x,[5,5,1,32],[32])\n",
    "        # compress information\n",
    "        pool_1 = max_pool(conv_1)\n",
    "    \n",
    "    # second convolutional layer with 64 filters\n",
    "    # with spatial extent of 5\n",
    "    # input tensor of depth 32 -> depth 64\n",
    "    with tf.variable_scope(\"conv_2\"):\n",
    "        conv_2 = conv2d(pool_1,[5,5,32,64],[64])\n",
    "        pool_2 = max_pool(conv_2)\n",
    "    \n",
    "    # fully connected layer\n",
    "    # flaten the tesnor by computing the full size of each \"subtensor\" \n",
    "    # 64 filters corresponding to the depth of 64\n",
    "    # each feature map as a hieght and width of 7\n",
    "    with tf.variable_scope(\"fc\"):\n",
    "        pool_2_flat = tf.reshape(pool_2,[-1,7*7*64])\n",
    "        # compress the flattened representation into a hidden state of size 1024\n",
    "        fc_1 = layer(pool_2_flat,[7*7*64,1024],[1024])\n",
    "        \n",
    "        # apply dropout\n",
    "        # dropout probability 0.5 during training and 1 during evaluation\n",
    "        fc_1_drop = tf.nn.dropout(fc_1,keep_prob)\n",
    "        \n",
    "    # softmax output layer with 10 bins\n",
    "    with tf.variable_scope(\"output\"):\n",
    "        output = layer(fc_1_drop,[1024,10],[10])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Passing a `GraphDef` to the SummaryWriter is deprecated. Pass a `Graph` object instead, such as `sess.graph`.\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "\n",
    "        with tf.variable_scope(\"mnist_conv_model\"):\n",
    "\n",
    "            x = tf.placeholder(\"float\", [None, 784]) # mnist data image of shape 28*28=784\n",
    "            y = tf.placeholder(\"float\", [None, 10]) # 0-9 digits recognition => 10 classes\n",
    "            keep_prob = tf.placeholder(tf.float32) # dropout probability\n",
    "\n",
    "            output = inference(x, keep_prob)\n",
    "\n",
    "            cost = loss(output, y)\n",
    "\n",
    "            global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "\n",
    "            train_op = training(cost, global_step)\n",
    "\n",
    "            eval_op = evaluate(output, y)\n",
    "\n",
    "            summary_op = tf.merge_all_summaries()\n",
    "\n",
    "            saver = tf.train.Saver()\n",
    "\n",
    "            sess = tf.Session()\n",
    "\n",
    "            summary_writer = tf.train.SummaryWriter(\"conv_mnist_logs/\",graph_def=sess.graph_def)\n",
    "\n",
    "                \n",
    "            init_op = tf.initialize_all_variables()\n",
    "\n",
    "            sess.run(init_op)\n",
    "\n",
    "\n",
    "            # Training cycle\n",
    "            for epoch in range(training_epochs):\n",
    "\n",
    "                avg_cost = 0.\n",
    "                total_batch = int(mnist.train.num_examples/batch_size)\n",
    "                # Loop over all batches\n",
    "                for i in range(total_batch):\n",
    "                    minibatch_x, minibatch_y = mnist.train.next_batch(batch_size)\n",
    "                    # Fit training using batch data\n",
    "                    sess.run(train_op, feed_dict={x: minibatch_x, y: minibatch_y, keep_prob: 0.5})\n",
    "                    # Compute average loss\n",
    "                    avg_cost += sess.run(cost, feed_dict={x: minibatch_x, y: minibatch_y, keep_prob: 0.5})/total_batch\n",
    "                # Display logs per epoch step\n",
    "                if epoch % display_step == 0:\n",
    "                    print \"Epoch:\", '%04d' % (epoch+1), \"cost =\", \"{:.9f}\".format(avg_cost)\n",
    "\n",
    "                    accuracy = sess.run(eval_op, feed_dict={x: mnist.validation.images, y: mnist.validation.labels, keep_prob: 1})\n",
    "\n",
    "                    print \"Validation Error:\", (1 - accuracy)\n",
    "\n",
    "                    summary_str = sess.run(summary_op, feed_dict={x: minibatch_x, y: minibatch_y, keep_prob: 0.5})\n",
    "                    summary_writer.add_summary(summary_str, sess.run(global_step))\n",
    "\n",
    "                    saver.save(sess, \"conv_mnist_logs/model-checkpoint\", global_step=global_step)\n",
    "\n",
    "\n",
    "            print \"Optimization Finished!\"\n",
    "\n",
    "\n",
    "            accuracy = sess.run(eval_op, feed_dict={x: mnist.test.images, y: mnist.test.labels, keep_prob: 1})\n",
    "\n",
    "            print \"Test Accuracy:\", accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
